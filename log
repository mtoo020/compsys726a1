2/4/15 7:30pm - 12am
Set up working environment
Played around with real robots
Created OpenGL visualisation of sonar data
Created base code

3/4/15 1:30am - 4:50am
Added laser data to the visualisation
Confirmed index of left, right, front, back sonar and laser sensors in simulation

4/4/15 2am - 4:30am
Added movement methods

5/4/15 2pm - 4:30pm
Robot can now handle starting off at any angle

7/4/15 1:30am - 3am
Robot can now detect side rooms, objects and humans and ask if the person is ok

7/4/15 6:30pm - 10pm
Tested code on a real robot, refined algorithm
Found the following:
Real robot
has only 180 degrees of sonar on some robots (360 in simulation and on other robots)
yaw is from 0-2pi (0 to pi/-pi to 0 in simulation)
uses wheel spin to determine yaw

8/4/15 6pm - 12am
Added speech thread and speech generation method
Improved turning accuracy
Made adjustments to threshold values

14/4/15 3pm-12am
Robot can now turn and face a room

18/4/15 3pm-12am
Nearly done


